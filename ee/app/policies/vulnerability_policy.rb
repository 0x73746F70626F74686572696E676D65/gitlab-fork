# frozen_string_literal: true

class VulnerabilityPolicy < BasePolicy
  AI_ALLOWED_REPORT_TYPES = %w[sast].freeze

  delegate(:project) { @subject.project }

  # Only users who can read vulnerability can comment.
  # It would not be safe to prevent :create_note in project policy,
  # since note permissions are shared, and this can have ripple effect on other parts.
  rule { ~can?(:read_security_resource) }.prevent :create_note
  rule { can?(:read_security_resource) }.enable :read_vulnerability

  # Only SAST findings can be explained or resolved via AI
  condition(:ai_allowed_finding_present, scope: :subject) do
    subject.finding.present? && AI_ALLOWED_REPORT_TYPES.include?(subject.report_type)
  end

  # Resolve vulnerability feature flag check
  condition(:resolve_vulnerability_with_ai_enabled, scope: :subject) do
    ::Feature.enabled?(:resolve_vulnerability_ai, subject.project)
  end

  # Authorize access to Explain Vulnerability
  condition(:explain_vulnerability_with_ai_authorized, scope: :subject) do
    ::Gitlab::Llm::Chain::Utils::ChatAuthorizer.resource(
      resource: subject,
      user: @user
    ).allowed?
  end

  # Authorize access to Resolve Vulnerability
  condition(:resolve_vulnerability_with_ai_authorized, scope: :subject) do
    ::Gitlab::Llm::FeatureAuthorizer.new(
      container: subject.project,
      feature_name: :resolve_vulnerability
    ).allowed?
  end

  rule do
    can?(:read_security_resource) &
      ai_allowed_finding_present &
      explain_vulnerability_with_ai_authorized
  end.enable(:explain_vulnerability_with_ai)

  rule do
    resolve_vulnerability_with_ai_enabled &
      can?(:read_security_resource) &
      ai_allowed_finding_present &
      resolve_vulnerability_with_ai_authorized
  end.enable(:resolve_vulnerability_with_ai)

  rule { can?(:admin_vulnerability) }.enable :create_external_issue_link
  rule { project.security_dashboard_enabled & can?(:developer_access) }.enable :create_external_issue_link
end
