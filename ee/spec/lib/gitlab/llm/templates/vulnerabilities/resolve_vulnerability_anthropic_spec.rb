# frozen_string_literal: true

require 'spec_helper'

RSpec.describe Gitlab::Llm::Templates::Vulnerabilities::ResolveVulnerabilityAnthropic,
  feature_category: :vulnerability_management do
  let(:source_code) do
    <<~SOURCE
    #include <stdio.h>

    int main(int argc, char *argv[])
    {
      char buf[8];
      memcpy(&buf, "123456789");
      printf("hello, world!");
    }
    SOURCE
  end

  let(:project) do
    create(:project, :custom_repo, files: {
      'src/main.c' => source_code
    })
  end

  let(:vulnerability_finding) do
    create(:vulnerabilities_finding,
      :sast,
      project: project,
      location: {
        'file' => 'src/main.c',
        'start_line' => 5,
        'end_line' => 6
      },
      identifiers: [build(:vulnerabilities_identifier, name: 'CWE-0000')]
    )
  end

  let(:vulnerability) do
    create(:vulnerability, :sast, findings: [vulnerability_finding], project: project, title: 'Severe vulnerability')
  end

  describe '#to_prompt' do
    subject(:result) { described_class.new(vulnerability, nil).to_prompt }

    it 'returns expected prompt', :aggregate_failures do
      expected_system_prompt = <<~PROMPT.chomp
        You are a software vulnerability developer.
        You can write code that fixes vulnerabilities.
        You just respond with a code fragment, no need to explain it.
        The code is written in C and stored as "main.c".
      PROMPT

      expected_user_prompt = <<~PROMPT.chomp
        The file "main.c" has this vulnerable code:

        ```
          char buf[8];
          memcpy(&buf, "123456789");
        ```

        It has the security vulnerability "Severe vulnerability - (CWE-0000)". Write code that fixes the vulnerability.
      PROMPT

      expected_messages = [
        {
          role: :user, content: expected_user_prompt
        }
      ]
      expect(result[:messages]).to eq(expected_messages)
      expect(result[:system]).to eq(expected_system_prompt)
      expect(result[:model]).to eq(::Gitlab::Llm::Concerns::AvailableModels::CLAUDE_3_HAIKU)
    end

    describe 'code is not eligible' do
      context 'when there is no source code in the finding' do
        let(:source_code) { nil }

        it 'raises an error' do
          expect { result }.to raise_error(Gitlab::Llm::Templates::Vulnerabilities::PromptError,
            /Unable to locate source code for vulnerability/)
        end
      end

      context 'when the code exceeds the maximum length' do
        let(:max_code_length) { Gitlab::Llm::Chain::Concerns::AnthropicPrompt::MAX_CHARACTERS / 10 }
        let(:source_code) { 'x' * (max_code_length + 1) }

        before do
          vulnerability.finding.location['start_line'] = 1
        end

        it 'raises an error' do
          expect { result }.to raise_error(Gitlab::Llm::Templates::Vulnerabilities::PromptError,
            /Vulnerable code exceeds maximum length \(#{max_code_length}\)/)
        end
      end

      context 'when the finding is a secret detection' do
        before do
          vulnerability.report_type = :secret_detection
        end

        it 'raises an error' do
          expect { result }.to raise_error(Gitlab::Llm::Templates::Vulnerabilities::PromptError,
            /Refusing to send possible secrets in AI prompt/)
        end
      end
    end
  end
end
