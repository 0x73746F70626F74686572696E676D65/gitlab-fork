# frozen_string_literal: true

require 'spec_helper'

RSpec.describe Gitlab::Llm::Completions::ResolveVulnerability, feature_category: :vulnerability_management do
  let(:prompt_class) { Gitlab::Llm::Templates::Vulnerabilities::ResolveVulnerability }
  let(:merge_request_service) { ::MergeRequests::CreateFromVulnerabilityDataService }
  let(:merge_request) { create(:merge_request, source_project: project) }
  let(:mr_url) { Gitlab::Routing.url_helpers.project_merge_request_url(project, merge_request) }
  let(:code_patch) { "somecode\nexecute" }
  let(:finding_location_file) { 'main.c' }
  let(:example_response) do
    {
      "predictions" => [
        {
          "content" => "```\n#{code_patch}\n```",
          "safetyAttributes" => {
            "categories" => ["Violent"],
            "scores" => [0.4000000059604645],
            "blocked" => false
          }
        }
      ],
      "deployedModelId" => "1",
      "model" => "projects/1/locations/us-central1/models/codechat-bison-001",
      "modelDisplayName" => "codechat-bison-001",
      "modelVersionId" => "1"
    }
  end

  let(:error_response) do
    { 'error' => { 'message' => 'Ooops...' } }
  end

  let(:errors) do
    ["Ooops..."]
  end

  let_it_be(:user) { create(:user) }
  let_it_be(:user2) { create(:user) }
  let_it_be(:project) do
    create(:project, :custom_repo, files: {
      'main.c' => "#include <stdio.h>\n\nint main() { printf(\"hello, world!\"); }"
    })
  end

  let(:vulnerability) { create(:vulnerability, :with_finding, project: project) }

  let(:prompt_message) do
    build(:ai_message, :resolve_vulnerability, user: user, resource: vulnerability, request_id: 'uuid')
  end

  let(:options) { {} }

  subject(:resolve) { described_class.new(prompt_message, prompt_class, options) }

  def execute_resolve(message_params = {}, options = {})
    message = build(:ai_message, :resolve_vulnerability,
      { user: user, resource: vulnerability, request_id: 'uuid' }.merge(message_params))

    described_class.new(message, prompt_class, options).execute
  end

  before_all do
    project.add_developer(user)
    project.add_developer(user2)
  end

  before do
    stub_licensed_features(security_dashboard: true)

    allow(GraphqlTriggers).to receive(:ai_completion_response)
    vulnerability.finding.location['file'] = finding_location_file
    vulnerability.finding.location['start_line'] = 1
  end

  shared_examples 'resolve vulnerability completions' do |llm_client, client_method|
    context 'when the client returns an unsuccessful response' do
      before do
        allow_next_instance_of(llm_client) do |client|
          allow(client).to receive(client_method).and_return(
            error_response
          )
        end
      end

      it 'publishes the error to the graphql subscription' do
        resolve.execute

        expect(GraphqlTriggers).to have_received(:ai_completion_response)
          .with(an_object_having_attributes(
            user: user,
            resource: vulnerability,
            role: ::Gitlab::Llm::AiMessage::ROLE_ASSISTANT,
            request_id: 'uuid',
            errors: errors
          ))
      end
    end

    context 'when there is no file for the finding in the repo' do
      let(:finding_location_file) { 'no_such_file.c' }

      it 'returns an error' do
        resolve.execute

        expect(GraphqlTriggers).to have_received(:ai_completion_response)
          .with(an_object_having_attributes(
            user: user,
            resource: vulnerability,
            role: ::Gitlab::Llm::AiMessage::ROLE_ASSISTANT,
            request_id: 'uuid',
            errors: ['Unable to generate prompt for Vulnerability']
          ))
      end
    end

    context 'when the client returns a successful response' do
      before do
        allow(llm_client).to receive(:new).and_call_original
        allow_next_instance_of(llm_client) do |client|
          allow(client).to receive(client_method).and_return(example_response)
        end

        allow(merge_request_service).to receive(:new).and_call_original
        allow_next_instance_of(merge_request_service) do |mr_service|
          allow(mr_service).to receive(:execute).and_return(
            { merge_request: merge_request, status: :success }
          )
        end
      end

      it 'requests that a MR be created with the extracted patch' do
        resolve.execute

        expect(merge_request_service).to have_received(:new).with(
          project,
          vulnerability,
          user,
          llm_patch: code_patch
        )
      end

      it 'publishes the created merge request for the fix' do
        resolve.execute

        expect(GraphqlTriggers).to have_received(:ai_completion_response).with(
          an_object_having_attributes(
            content: mr_url,
            role: ::Gitlab::Llm::AiMessage::ROLE_ASSISTANT,
            request_id: 'uuid',
            errors: [],
            user: user,
            resource: vulnerability
          )
        )
      end

      context 'when an unexpected error is raised' do
        let(:error) { StandardError.new("Ooops...") }

        before do
          allow_next_instance_of(llm_client) do |client|
            allow(client).to receive(client_method).and_raise(error)
          end
          allow(Gitlab::ErrorTracking).to receive(:track_exception)
        end

        it 'records the error' do
          resolve.execute
          expect(Gitlab::ErrorTracking).to have_received(:track_exception).with(error)
        end

        it 'publishes a generic error to the graphql subscription' do
          resolve.execute

          expect(GraphqlTriggers).to have_received(:ai_completion_response).with(
            an_object_having_attributes(
              role: ::Gitlab::Llm::AiMessage::ROLE_ASSISTANT,
              request_id: 'uuid',
              errors: [described_class::DEFAULT_ERROR],
              user: user,
              resource: vulnerability
            ))
        end
      end

      context 'when the client experiences a Net::ReadTimeout' do
        let(:error) { Net::ReadTimeout.new }

        before do
          allow_next_instance_of(llm_client) do |client|
            allow(client).to receive(client_method).and_raise(error)
          end
          allow(Gitlab::ErrorTracking).to receive(:track_exception)
        end

        it 'records the error' do
          resolve.execute
          expect(Gitlab::ErrorTracking).to have_received(:track_exception).with(error)
        end

        it 'publishes a generic error to the graphql subscription' do
          resolve.execute

          expect(GraphqlTriggers).to have_received(:ai_completion_response).with(
            an_object_having_attributes(
              role: ::Gitlab::Llm::AiMessage::ROLE_ASSISTANT,
              request_id: 'uuid',
              errors: [described_class::CLIENT_TIMEOUT_ERROR],
              user: user,
              resource: vulnerability
            ))
        end
      end

      context 'when the CreateFromVulnerabilityDataService service fails to create an MR' do
        before do
          allow_next_instance_of(::MergeRequests::CreateFromVulnerabilityDataService) do |service|
            allow(service).to receive(:execute).and_return({ result: :failed })
          end
          allow(Gitlab::ErrorTracking).to receive(:track_exception)
        end

        it 'publishes a resolution error to the graphql subscription' do
          resolve.execute

          expect(GraphqlTriggers).to have_received(:ai_completion_response).with(
            an_object_having_attributes(
              role: ::Gitlab::Llm::AiMessage::ROLE_ASSISTANT,
              request_id: 'uuid',
              errors: [described_class::RESOLUTION_FAILURE_ERROR],
              user: user,
              resource: vulnerability
            ))
        end
      end

      context 'when request is cached', :use_clean_rails_redis_caching do
        context 'when unique users make the same request' do
          let(:fake_client) { instance_double(llm_client) }

          before do
            allow(llm_client).to receive(:new).and_return(fake_client)
            allow(fake_client).to receive(client_method).twice.and_return(example_response)
          end

          it 'makes a fresh request for each user' do
            # cache miss
            execute_resolve
            execute_resolve({ user: user2 })

            # cache hit
            execute_resolve
            execute_resolve({ user: user2 })

            expect(fake_client).to have_received(client_method).exactly(2).times
          end
        end
      end
    end
  end

  describe '#execute', :clean_gitlab_redis_cache do
    let(:tracking_context) { { request_id: "uuid", action: :resolve_vulnerability } }

    it_behaves_like 'resolve vulnerability completions', ::Gitlab::Llm::VertexAi::Client, :code do
      let(:extra_arguments) { { tracking_context: tracking_context } }
    end
  end
end
