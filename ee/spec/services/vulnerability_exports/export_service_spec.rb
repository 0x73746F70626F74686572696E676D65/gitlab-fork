# frozen_string_literal: true

require 'spec_helper'

RSpec.describe VulnerabilityExports::ExportService, feature_category: :vulnerability_management do
  let_it_be(:group) { create(:group, name: "ðŸ”’ gitlab", path: 'gitlab') }
  let_it_be(:project_a) { create(:project, group: group) }

  describe '::export' do
    let(:vulnerability_export) { create(:vulnerability_export) }
    let(:mock_service_object) { instance_double(described_class, export: true) }

    subject(:export) { described_class.export(vulnerability_export) }

    before do
      allow(described_class).to receive(:new).and_return(mock_service_object)
    end

    it 'instantiates a new instance of the service class and sends export message to it' do
      export

      expect(described_class).to have_received(:new).with(vulnerability_export)
      expect(mock_service_object).to have_received(:export)
    end
  end

  describe '#export_segment' do
    let!(:vulnerability_export) { create(:vulnerability_export, :created, group: group, project: nil) }
    let!(:vulnerabilities) { create_list(:vulnerability, 3, :with_read, project: project_a) }
    let!(:vulnerability_export_part) do
      create(
        :vulnerability_export_part,
        vulnerability_export: vulnerability_export,
        start_id: project_a.vulnerabilities.first.id,
        end_id: project_a.vulnerabilities.last.id
      )
    end

    let(:service_object) { described_class.new(vulnerability_export) }

    subject(:export_segment) { service_object.export_segment(vulnerability_export_part) }

    it 'generates the exported segment file' do
      expect(VulnerabilityExports::ExportDeletionWorker).not_to receive(:perform_async)

      export_segment

      csv = CSV.read(vulnerability_export_part.reload.file.path, headers: true)

      expect(csv.headers).to be_present
      expect(csv['Vulnerability']).to match_array(vulnerabilities.map(&:title))
    end

    context 'when the export fails' do
      before do
        allow(vulnerability_export_part).to receive(:start_id).and_raise(RuntimeError)
      end

      it 'raises an error and cleans up the export' do
        expect(VulnerabilityExports::ExportDeletionWorker).to receive(:perform_in).with(1.hour, vulnerability_export.id)

        expect { export_segment }.to raise_error(RuntimeError)

        expect(vulnerability_export.reload.status).to eq('failed')
      end
    end
  end

  describe '#finalise_segmented_export' do
    let!(:vulnerability_export) { create(:vulnerability_export, :running, group: group, project: nil) }
    let!(:vulnerabilities) { create_list(:vulnerability, 3, :with_read, project: project_a) }
    let!(:vulnerbility_export_part_1) do
      create(
        :vulnerability_export_part,
        vulnerability_export: vulnerability_export,
        start_id: vulnerabilities.first.id,
        end_id: vulnerabilities.second.id,
        file: write_tempfile("dontshow,\n123,456,789\n")
      )
    end

    let!(:vulnerbility_export_part_2) do
      create(
        :vulnerability_export_part,
        vulnerability_export: vulnerability_export,
        start_id: vulnerabilities.last.id,
        end_id: vulnerabilities.last.id,
        file: write_tempfile("dontshow,\n987,654,321\n")
      )
    end

    let(:vulnerability_export_parts) { [vulnerbility_export_part_1, vulnerbility_export_part_2] }
    let(:service_object) { described_class.new(vulnerability_export) }

    subject(:finalise_segmented_export) { service_object.finalise_segmented_export }

    it 'merges the exported segments into one file, dropping excess headers' do
      expect(VulnerabilityExports::ExportDeletionWorker).to receive(:perform_in).with(1.hour, vulnerability_export.id)
      expect(vulnerability_export).to receive(:export_parts).and_return(vulnerability_export_parts)
      expect(vulnerbility_export_part_1).to receive(:file).and_call_original
      expect(vulnerbility_export_part_2).to receive(:file).and_call_original
      allow(service_object).to receive(:export_header).and_return("headerline,headerline,headerline,\n")

      expect { finalise_segmented_export }.to change { vulnerability_export.reload.file.filename }

      expect(vulnerability_export.reload.file.read).to eq(
        "headerline,headerline,headerline,\n123,456,789\n987,654,321\n"
      )
      expect(vulnerability_export.reload.status).to eq('finished')
    end

    context 'when the export fails' do
      before do
        allow(vulnerability_export).to receive(:export_parts).and_raise(RuntimeError)
      end

      it 'raises an error and cleans up the export' do
        expect(VulnerabilityExports::ExportDeletionWorker).to receive(:perform_in).with(1.hour, vulnerability_export.id)

        expect { finalise_segmented_export }.to raise_error(RuntimeError)

        expect(vulnerability_export.reload.status).to eq('failed')
      end
    end
  end

  shared_examples 'does not make use of segmented exports' do
    it do
      expect(::Vulnerabilities::Export::Part).not_to receive(:create!)
      expect(::Gitlab::Export::SegmentedExportWorker).not_to receive(:perform_async)

      export

      csv = CSV.read(vulnerability_export.reload.file.path, headers: true)

      expect(csv.headers).to be_present
    end
  end

  describe '#export' do
    let!(:vulnerability_export) { create(:vulnerability_export, :created) }
    let(:service_object) { described_class.new(vulnerability_export) }

    subject(:export) { service_object.export }

    context 'generating the export file' do
      let(:lease_name) { "vulnerability_exports_export:#{vulnerability_export.id}" }

      before do
        allow(service_object).to receive(:in_lock)
      end

      it 'runs synchronized with distributed semaphore' do
        export

        expect(service_object).to have_received(:in_lock).with(lease_name, ttl: 1.hour)
      end
    end

    context 'when the vulnerability_export is not in `created` state' do
      before do
        allow(vulnerability_export).to receive(:created?).and_return(false)
        allow(service_object).to receive(:generate_export)
      end

      it 'does not execute export file generation logic' do
        export

        expect(service_object).not_to have_received(:generate_export)
      end
    end

    context 'when the vulnerability_export is in `created` state' do
      context 'when the exportable is a group' do
        let!(:vulnerability_export) { create(:vulnerability_export, :created, group: group, project: nil) }

        context 'when the vulnerabilities are more than the partial file batch size' do
          let!(:vulnerabilities) { create_list(:vulnerability, 3, :with_read, project: project_a) }
          let(:segmented_export_workers_count) { 5 }
          let(:vuln_export_1) { instance_double(::Vulnerabilities::Export::Part, id: 1234) }
          let(:vuln_export_2) { instance_double(::Vulnerabilities::Export::Part, id: 4321) }

          before do
            stub_const('VulnerabilityExports::ExportService::VULNERABILITY_READS_PARTIAL_FILE_BATCH_SIZE', 2)
            stub_const('VulnerabilityExports::ExportService::SEGMENTED_EXPORT_WORKERS', segmented_export_workers_count)
          end

          context 'when segmented_vulnerability_report_export is enabled' do
            it 'generates the export file in batches, scaling workers to the number of parts needed' do
              expect(::Vulnerabilities::Export::Part).to receive(:create).with(
                vulnerability_export_id: vulnerability_export.id,
                start_id: vulnerabilities.first.id,
                end_id: vulnerabilities.second.id
              ).and_return(vuln_export_1)
              expect(::Vulnerabilities::Export::Part).to receive(:create).with(
                vulnerability_export_id: vulnerability_export.id,
                start_id: vulnerabilities.last.id,
                end_id: vulnerabilities.last.id
              ).and_return(vuln_export_2)

              expect(::Gitlab::Export::SegmentedExportWorker).to receive(:perform_async).with(
                vulnerability_export.to_global_id,
                [vuln_export_1.id]
              )
              expect(::Gitlab::Export::SegmentedExportWorker).to receive(:perform_async).with(
                vulnerability_export.to_global_id,
                [vuln_export_2.id]
              )

              export
            end

            context 'when an error occurs during the enqueuing' do
              before do
                allow(::Gitlab::Export::SegmentedExportWorker).to receive(:perform_async).and_raise(StandardError)
              end

              it 'raises an error and cleans up the export' do
                expect(VulnerabilityExports::ExportDeletionWorker).to receive(:perform_in).with(1.hour, vulnerability_export.id)
                expect { export }.to raise_error(StandardError)
                expect(vulnerability_export.reload.status).to eq('failed')
              end
            end

            context 'when there are many vulnerabilities' do
              let!(:more_vulnerabilities) { create_list(:vulnerability, 6, project: project_a) }
              let(:segmented_export_workers_count) { 1 }
              let!(:organization) { create(:organization, id: 1) }

              it 'does not create more export workers than SEGMENTED_EXPORT_WORKERS' do
                expect(::Gitlab::Export::SegmentedExportWorker).to receive(:perform_async).exactly(
                  segmented_export_workers_count
                ).times

                export
              end
            end

            context 'when segmented_vulnerability_report_export is disabled' do
              before do
                stub_feature_flags(segmented_vulnerability_report_export: false)
              end

              it_behaves_like 'does not make use of segmented exports'
            end
          end
        end
      end

      context 'when the exportable is a project' do
        let!(:vulnerability_export) { create(:vulnerability_export, :created, group: nil, project: project_a) }

        context 'when segmented_vulnerability_report_export is enabled' do
          it_behaves_like 'does not make use of segmented exports'
        end

        context 'when segmented_vulnerability_report_export is disabled' do
          before do
            stub_feature_flags(segmented_vulnerability_report_export: false)
          end

          it_behaves_like 'does not make use of segmented exports'
        end
      end

      context 'when segmented_vulnerability_report_export is disabled' do
        before do
          stub_feature_flags(segmented_vulnerability_report_export: false)
          allow(VulnerabilityExports::ExportDeletionWorker).to receive(:perform_in)
        end

        context 'when the export generation fails' do
          let(:error) { RuntimeError.new('foo') }

          before do
            allow(service_object).to receive(:generate_export_file).and_raise(error)
          end

          it 'sets the state of export back to `created`' do
            expect { export }.to raise_error(error)
            expect(vulnerability_export.reload.created?).to be_truthy
          end

          it 'schedules the export deletion background job' do
            expect { export }.to raise_error(error)
            expect(VulnerabilityExports::ExportDeletionWorker).to have_received(:perform_in).with(1.hour, vulnerability_export.id)
          end
        end

        context 'when the export generation succeeds' do
          before do
            allow(service_object).to receive(:generate_export_file)
            allow(vulnerability_export).to receive(:start!)
            allow(vulnerability_export).to receive(:finish!)
          end

          it 'marks the state of export object as `started` and then `finished`' do
            export

            expect(vulnerability_export).to have_received(:start!).ordered
            expect(vulnerability_export).to have_received(:finish!).ordered
          end

          it 'schedules the export deletion background job' do
            export

            expect(VulnerabilityExports::ExportDeletionWorker).to have_received(:perform_in).with(1.hour, vulnerability_export.id)
          end
        end

        context 'when the export format is csv' do
          let(:vulnerabilities) { Vulnerability.none }
          let(:mock_relation) { double(:relation, with_findings_scanner_identifiers_and_notes: vulnerabilities) }
          let(:mock_vulnerability_finder_service_object) { instance_double(Security::VulnerabilitiesFinder, execute: mock_relation) }
          let(:exportable_full_path) { 'foo' }
          let(:time_suffix) { Time.current.utc.strftime('%FT%H%M') }
          let(:expected_file_name) { "#{exportable_full_path}_vulnerabilities_#{time_suffix}.csv" }

          before do
            allow(Security::VulnerabilitiesFinder).to receive(:new).and_return(mock_vulnerability_finder_service_object)
            allow(vulnerability_export.exportable).to receive(:full_path).and_return(exportable_full_path)
          end

          around do |example|
            freeze_time { example.run }
          end

          it 'calls the VulnerabilityExports::Exporters::CsvService which sets the file and filename' do
            expect { export }.to change { vulnerability_export.file }
                            .and change { vulnerability_export.file&.filename }.from(nil).to(expected_file_name)
          end

          context 'when generating an export for a group' do
            let_it_be(:group_b) { create(:group, parent: group) }
            let_it_be(:project_b) { create(:project, group: group_b) }
            let_it_be(:project_c) { create(:project, :archived, group: group_b) }
            let_it_be(:vulnerabilities_a) { create_list(:vulnerability, 2, :detected, :with_read, project: project_a) }
            let_it_be(:vulnerabilities_b) { create_list(:vulnerability, 2, :detected, :with_read, project: project_b) }
            let_it_be(:vulnerabilities_c) { create_list(:vulnerability, 2, :detected, :with_read, project: project_c) }

            let(:vulnerability_export) { create(:vulnerability_export, :csv, group: group, project: nil) }

            describe 'N+1 queries' do
              before do
                vulnerabilities_a.each { |vulnerability| vulnerability.update!(state: :dismissed) }
              end

              it 'avoids N+1 queries' do
                export_2 = create(:vulnerability_export, :csv, group: group_b, project: nil)
                control = ActiveRecord::QueryRecorder.new(skip_cached: false) { described_class.new(export_2).export }

                expect { export }.not_to exceed_query_limit(control)
              end
            end

            it 'updates the state of the export' do
              export

              expect(vulnerability_export.finished_at).to be_present
              expect(vulnerability_export).to be_finished
              expect(vulnerability_export).to be_completed
            end

            it 'appends each vulnerability to a CSV file' do
              export

              csv = CSV.read(vulnerability_export.file.path, headers: true)

              expect(csv.headers).to be_present
              expect(csv['Vulnerability']).to match_array(
                vulnerabilities_a.map(&:title) +
                vulnerabilities_b.map(&:title)
              )
            end

            context 'with `optimized_vulnerability_report_export` disabled' do
              before do
                stub_feature_flags(optimized_vulnerability_report_export: false)
              end

              it 'appends each vulnerability to a CSV file' do
                export

                csv = CSV.read(vulnerability_export.file.path, headers: true)

                expect(csv.headers).to be_present
                expect(csv['Vulnerability']).to match_array(
                  vulnerabilities_a.map(&:title) +
                  vulnerabilities_b.map(&:title)
                )
              end
            end
          end
        end
      end
    end
  end

  # Using Tempfile.open closes the stream after the block, making the reference useless.
  def write_tempfile(body)
    f = Tempfile.new
    f << body
    f.rewind
    f
  end
end
