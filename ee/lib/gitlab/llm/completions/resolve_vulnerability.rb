# frozen_string_literal: true

module Gitlab
  module Llm
    module Completions
      class ResolveVulnerability < Gitlab::Llm::Completions::Base
        DEFAULT_ERROR = 'An unexpected error has occurred.'
        CLIENT_TIMEOUT_ERROR = 'The upstream AI provider request timed out without responding.'
        FORBIDDEN_ERROR = "Unfortunately, you don't have access to vulnerability resolution."
        RESOLUTION_FAILURE_ERROR = 'Something went wrong while attempting to apply the ' \
                                   'AI resolution to a merge request.'
        MR_LINK_ERROR = 'An error occurred while attempting to link the MR to the vulnerability.'

        # Extract the first triple ` quoted code from the llm response with a named capture group called "change".
        # Important that the `.+` syntax be permitted to match over newlines.
        LLM_DIFF_REGEX = /```\w*\n(?<change>.+?)\n```/ms

        def execute
          ai_response, diff_extracted = response_for(user, vulnerability, options)

          response = diff_extracted ? create_merge_request(user, vulnerability, ai_response) : ai_response
          response_modifier = modify_response(response, vulnerability)

          ::Gitlab::Llm::GraphqlSubscriptionResponseService.new(
            user, vulnerability, response_modifier, options: response_options
          ).execute

          response_modifier
        rescue StandardError => error
          Gitlab::ErrorTracking.track_exception(error)

          response = formatted_error_response(error_message(error))
          response_modifier = modify_response(response, vulnerability)
          ::Gitlab::Llm::GraphqlSubscriptionResponseService.new(
            user, vulnerability, response_modifier, options: response_options
          ).execute

          response_modifier
        end

        def response_for(user, vulnerability, options)
          Rails.cache.fetch(cache_key(user, vulnerability), expires_in: 10.minutes, skip_nil: true) do
            if Feature.enabled?(:resolve_vulnerability_ai_gateway, vulnerability.project)
              @ai_prompt_class = ::Gitlab::Llm::Templates::Vulnerabilities::ResolveVulnerabilityAnthropic
              prompt = ai_prompt_class.new(vulnerability, options).to_prompt
              ai_response = anthropic_request(user, prompt)
            else
              prompt = ai_prompt_class.new(vulnerability, options).to_prompt
              ai_response = vertex_request(user, prompt, vulnerability)
            end

            extract_llm_change(ai_response)
          end
        end

        private

        def extract_llm_change(ai_response)
          content = ai_response.dig('predictions', 0, 'content') || ai_response.dig('content', 0, 'text')
          match_data = content.to_s.match(LLM_DIFF_REGEX)
          return [ai_response, false] unless match_data

          [match_data[:change], true]
        end

        def create_merge_request(user, vulnerability, response)
          return unless response.present? && !@null_prompt_error

          merge_request_result = ::MergeRequests::CreateFromVulnerabilityDataService.new(
            vulnerability.project,
            vulnerability,
            user,
            llm_patch: response
          ).execute

          unless merge_request_result[:status] == :success
            return formatted_error_response(RESOLUTION_FAILURE_ERROR,
              context: merge_request_result)
          end

          merge_request = merge_request_result[:merge_request]

          mr_link_result = VulnerabilityMergeRequestLinks::CreateService.new(
            project: vulnerability.project,
            current_user: user,
            params: {
              vulnerability: vulnerability,
              merge_request: merge_request
            }
          ).execute

          unless mr_link_result[:status] == :success
            return formatted_error_response(MR_LINK_ERROR,
              context: mr_link_result)
          end

          mr_url = Gitlab::Routing.url_helpers.project_merge_request_url(
            merge_request.project,
            merge_request
          )

          { merge_request_url: mr_url }
        end

        def error_message(error)
          case error
          when Gitlab::Llm::Templates::Vulnerabilities::PromptError
            error.message
          when Net::ReadTimeout
            CLIENT_TIMEOUT_ERROR
          when Gitlab::AiGateway::ForbiddenError
            FORBIDDEN_ERROR
          else
            DEFAULT_ERROR
          end
        end

        def formatted_error_response(message, context = {})
          { error: { message: message, context: context } }.to_json
        end

        def modify_response(response, _vulnerability)
          ::Gitlab::Llm::ResponseModifiers::ResolveVulnerability.new(response)
        end

        def vertex_request(user, prompt, _vulnerability)
          ::Gitlab::Llm::VertexAi::Client.new(user,
            unit_primitive: 'resolve_vulnerability',
            tracking_context: tracking_context
          ).code(content: prompt)
        end

        def anthropic_request(user, prompt)
          ::Gitlab::Llm::ResolveVulnerability::Client.new(user,
            unit_primitive: 'resolve_vulnerability',
            tracking_context: tracking_context
          ).messages_complete(**prompt)
        end

        def cache_key(user, vulnerability)
          [user.id, vulnerability.cache_key, 'resolve'].join('/')
        end

        def vulnerability
          resource
        end
      end
    end
  end
end
