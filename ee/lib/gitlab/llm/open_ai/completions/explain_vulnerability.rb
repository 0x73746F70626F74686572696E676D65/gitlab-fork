# frozen_string_literal: true

module Gitlab
  module Llm
    module OpenAi
      module Completions
        class ExplainVulnerability < Gitlab::Llm::Completions::Base
          DEFAULT_ERROR = 'An unexpected error has occurred.'

          def execute(user, vulnerability, _options)
            template = ai_prompt_class.new(vulnerability)
            response = response_for(user, template)

            ::Gitlab::Llm::OpenAi::ResponseService
              .new(user, vulnerability, response, options: { request_id: params[:request_id] })
              .execute(Gitlab::Llm::OpenAi::ResponseModifiers::Chat.new)
          rescue StandardError => error
            Gitlab::ErrorTracking.track_exception(error)

            ::Gitlab::Llm::OpenAi::ResponseService
              .new(user, vulnerability, { error: { message: DEFAULT_ERROR } }.to_json,
                options: { request_id: params[:request_id] })
              .execute
          end

          private

          def response_for(user, template)
            client_class = ::Gitlab::Llm::OpenAi::Client
            client_class
              .new(user)
              .chat(content: template.to_prompt, **template.options(client_class))
          end
        end
      end
    end
  end
end
